---
sidebar_position: 3
title: Performance Recommendations
---

# Cajun Actor System: Performance Optimization Recommendations

Based on a thorough analysis of the Cajun codebase, here are comprehensive recommendations for improving performance across different components of the system.

## Actor Message Processing

### Bottlenecks Identified:
- Default batch size (10) may not be optimal for all workloads
- Message processing in `Actor.processMailbox()` creates a new ArrayList for each batch
- Mailbox implementation uses LinkedBlockingQueue which can be a bottleneck under high contention

### Recommendations:
1. **Adaptive Batch Sizing**:
   ```java
   // Add to Actor.java
   private int calculateOptimalBatchSize() {
       // Start with small batch size
       int currentSize = 10;
       // Increase if mailbox consistently has more messages
       if (mailbox.size() > currentSize * 2) {
           return Math.min(100, currentSize * 2);
       }
       return currentSize;
   }
   ```

2. **Reuse Batch Collections**:
   ```java
   // Modify Actor.processMailbox() to reuse the batch ArrayList
   private final List<Message> batchBuffer = new ArrayList<>(DEFAULT_BATCH_SIZE);
   
   protected void processMailbox() {
       while (isRunning) {
           try {
               batchBuffer.clear(); // Reuse the same list
               // Get at least one message (blocking)
               Message firstMessage = mailbox.take();
               batchBuffer.add(firstMessage);
               
               // Rest of the method remains the same
           }
           // ...
       }
   }
   ```

3. **Alternative Mailbox Implementations**:
   - For high-throughput scenarios, consider using a more specialized queue:
   ```java
   // Add to Actor constructor
   public Actor(ActorSystem system, String actorId, MailboxType mailboxType) {
       // ...
       switch (mailboxType) {
           case HIGH_THROUGHPUT:
               this.mailbox = new MpscArrayQueue<>(1024); // Multiple Producer Single Consumer queue
               break;
           case BOUNDED:
               this.mailbox = new ArrayBlockingQueue<>(1000);
               break;
           case UNBOUNDED:
           default:
               this.mailbox = new LinkedBlockingQueue<>();
       }
       // ...
   }
   ```

## Thread Pool Configuration

### Bottlenecks Identified:
- Default thread pool configuration may not be optimal for all workloads
- Virtual threads are used by default, which is good for IO-bound workloads but may not be optimal for CPU-bound tasks
- No automatic tuning based on system load or actor behavior

### Recommendations:
1. **Workload-Specific Thread Pools**:
   ```java
   // Add to ThreadPoolFactory
   public enum WorkloadType {
       IO_BOUND,      // Many actors doing mostly IO operations
       CPU_BOUND,     // Fewer actors doing intensive computation
       MIXED          // A mix of IO and CPU operations
   }
   
   public ThreadPoolFactory optimizeFor(WorkloadType workloadType) {
       switch (workloadType) {
           case IO_BOUND:
               return setExecutorType(ThreadPoolType.VIRTUAL);
           case CPU_BOUND:
               return setExecutorType(ThreadPoolType.FIXED)
                      .setFixedPoolSize(Runtime.getRuntime().availableProcessors());
           case MIXED:
               return setExecutorType(ThreadPoolType.WORK_STEALING);
       }
       return this;
   }
   ```

2. **Monitoring and Auto-Tuning**:
   - Add metrics collection to automatically adjust thread pool settings:
   ```java
   // Add to ActorSystem
   private final ScheduledExecutorService metricsCollector = Executors.newSingleThreadScheduledExecutor();
   private final Map<String, ActorMetrics> actorMetrics = new ConcurrentHashMap<>();
   
   public void enableAutoTuning() {
       metricsCollector.scheduleAtFixedRate(this::adjustThreadPoolSettings, 1, 1, TimeUnit.MINUTES);
   }
   
   private void adjustThreadPoolSettings() {
       // Analyze metrics and adjust thread pool settings accordingly
       // ...
   }
   ```

## State Management

### Bottlenecks Identified:
- `StatefulActor` persists state after every change, which can be expensive
- State initialization blocks message processing
- No batching of state updates for efficiency

### Recommendations:
1. **Delayed/Batched State Persistence**:
   ```java
   // Add to StatefulActor
   private boolean stateChanged = false;
   private long lastPersistTime = 0;
   private static final long PERSIST_INTERVAL_MS = 1000; // 1 second
   
   @Override
   protected final void receive(Message message) {
       // ...
       if (newState != currentStateValue && (newState == null || !newState.equals(currentStateValue))) {
           currentState.set(newState);
           stateChanged = true;
           
           // Only persist periodically or if too many changes accumulated
           long now = System.currentTimeMillis();
           if (now - lastPersistTime > PERSIST_INTERVAL_MS) {
               persistState();
               lastPersistTime = now;
               stateChanged = false;
           }
       }
       // ...
   }
   
   @Override
   protected void postStop() {
       // Always persist on shutdown if there are pending changes
       if (stateChanged) {
           persistState().join();
       }
       super.postStop();
   }
   ```

2. **Asynchronous State Initialization**:
   - Improve the state initialization to not block the actor:
   ```java
   // Modify StatefulActor.initializeState()
   private CompletableFuture<Void> initializeState() {
       if (stateInitialized) {
           return CompletableFuture.completedFuture(null);
       }
       
       // Set a temporary state to allow processing while loading
       currentState.set(initialState);
       stateInitialized = true;
       
       return stateStore.get(stateKey)
               .thenApply(optionalState -> {
                   if (optionalState.isPresent()) {
                       currentState.set(optionalState.get());
                   }
                   logger.debug("Actor {} state initialized: {}", getActorId(), 
                               optionalState.isPresent() ? "from store" : "with initial state");
                   return null;
               })
               .exceptionally(e -> {
                   logger.error("Error loading state for actor {}", getActorId(), e);
                   return null;
               });
   }
   ```

## Cluster Communication

### Bottlenecks Identified:
- `ReliableMessagingSystem` creates a new socket connection for each message
- Serialization/deserialization overhead with `ObjectOutputStream`/`ObjectInputStream`
- No connection pooling or message batching across the network

### Recommendations:
1. **Connection Pooling**:
   ```java
   // Add to ReliableMessagingSystem
   private final Map<String, Queue<Socket>> connectionPools = new ConcurrentHashMap<>();
   private static final int MAX_POOL_SIZE = 10;
   
   private Socket getConnection(String targetSystemId) throws IOException {
       NodeAddress address = nodeAddresses.get(targetSystemId);
       if (address == null) {
           throw new IllegalArgumentException("Unknown target system ID: " + targetSystemId);
       }
       
       Queue<Socket> pool = connectionPools.computeIfAbsent(targetSystemId, k -> new ConcurrentLinkedQueue<>());
       Socket socket = pool.poll();
       
       if (socket == null || socket.isClosed()) {
           socket = new Socket();
           socket.connect(new InetSocketAddress(address.host, address.port), 5000);
       }
       
       return socket;
   }
   
   private void releaseConnection(String targetSystemId, Socket socket) {
       if (socket.isClosed()) return;
       
       Queue<Socket> pool = connectionPools.get(targetSystemId);
       if (pool != null && pool.size() < MAX_POOL_SIZE) {
           pool.offer(socket);
       } else {
           try {
               socket.close();
           } catch (IOException e) {
               logger.warn("Error closing socket", e);
           }
       }
   }
   ```

2. **Message Batching**:
   ```java
   // Add to ReliableMessagingSystem
   private final Map<String, List<PendingMessage>> pendingMessages = new ConcurrentHashMap<>();
   private static final int BATCH_SIZE = 50;
   private static final long BATCH_TIMEOUT_MS = 50; // 50ms
   
   private static class PendingMessage<T> {
       final String actorId;
       final T message;
       final String messageId;
       final DeliveryGuarantee deliveryGuarantee;
       final CompletableFuture<Void> future;
       
       // Constructor and getters
   }
   
   public <Message> CompletableFuture<Void> sendMessage(
           String targetSystemId, String actorId, Message message, DeliveryGuarantee deliveryGuarantee) {
       
       CompletableFuture<Void> future = new CompletableFuture<>();
       
       String messageId = null;
       if (deliveryGuarantee != DeliveryGuarantee.AT_MOST_ONCE) {
           messageId = messageTracker.generateMessageId();
           messageTracker.trackOutgoingMessage(
               messageId, targetSystemId, actorId, message,
               this::retrySendMessage
           );
       }
       
       PendingMessage<Message> pendingMessage = new PendingMessage<>(
           actorId, message, messageId, deliveryGuarantee, future);
           
       List<PendingMessage> batch = pendingMessages.computeIfAbsent(
           targetSystemId, k -> Collections.synchronizedList(new ArrayList<>()));
           
       batch.add(pendingMessage);
       
       // If batch is full or this is the first message, schedule sending
       if (batch.size() >= BATCH_SIZE || batch.size() == 1) {
           scheduleBatchSend(targetSystemId);
       }
       
       return future;
   }
   
   private void scheduleBatchSend(String targetSystemId) {
       executor.schedule(() -> sendBatch(targetSystemId), BATCH_TIMEOUT_MS, TimeUnit.MILLISECONDS);
   }
   
   private void sendBatch(String targetSystemId) {
       List<PendingMessage> batch = pendingMessages.remove(targetSystemId);
       if (batch == null || batch.isEmpty()) return;
       
       // Send the batch in a single network operation
       // ...
   }
   ```

3. **More Efficient Serialization**:
   ```java
   // Replace ObjectOutputStream with a more efficient serialization mechanism
   // For example, using Protocol Buffers, FlatBuffers, or a custom binary format
   
   // Example with a hypothetical BinarySerializer
   private <Message> void doSendMessage(...) throws IOException {
       try (Socket socket = getConnection(targetSystemId)) {
           BinarySerializer serializer = new BinarySerializer(socket.getOutputStream());
           serializer.writeString(systemId);
           serializer.writeString(actorId);
           serializer.writeObject(message);
           serializer.writeString(messageId);
           serializer.writeInt(deliveryGuarantee.ordinal());
           serializer.flush();
           
           // Read acknowledgment if needed
           // ...
           
           releaseConnection(targetSystemId, socket);
       }
   }
   ```

## General System Optimizations

### Bottlenecks Identified:
- No prioritization of messages
- Potential for mailbox overflow under high load
- Limited metrics for performance monitoring

### Recommendations:
1. **Message Prioritization**:
   ```java
   // Add to Actor
   public enum MessagePriority {
       HIGH, NORMAL, LOW
   }
   
   private final PriorityBlockingQueue<PrioritizedMessage<Message>> priorityMailbox = 
       new PriorityBlockingQueue<>();
   
   private static class PrioritizedMessage<T> implements Comparable<PrioritizedMessage<T>> {
       final T message;
       final MessagePriority priority;
       final long timestamp;
       
       // Constructor and compareTo implementation
   }
   
   public void tell(Message message, MessagePriority priority) {
       priorityMailbox.offer(new PrioritizedMessage<>(message, priority, System.nanoTime()));
   }
   ```

2. **Backpressure Mechanisms**:
   ```java
   // Modern backpressure implementation with BackpressureManager
   private BackpressureManager<Message> backpressureManager;
   
   public void initializeBackpressure(BackpressureConfig config) {
       this.backpressureManager = new BackpressureManager<>(this, config);
       
       // Configure thresholds for state transitions
       backpressureManager.setThresholds(
           0.7f,  // WARNING threshold (70% capacity)
           0.8f,  // CRITICAL threshold (80% capacity)
           0.5f   // RECOVERY threshold (50% capacity)
       );
       
       // Set up monitoring callback
       backpressureManager.setCallback(event -> {
           if (event.isBackpressureActive()) {
               // Take action when backpressure is active
               logger.warn("Actor {} experiencing backpressure: {} fill ratio", 
                   getActorId(), event.getFillRatio());
           }
       });
   }
   
   public boolean tryTell(Message message, BackpressureSendOptions options) {
       // Check if message should be accepted based on backpressure state
       if (!backpressureManager.shouldAcceptMessage(options)) {
           return false; // Message rejected due to backpressure
       }
       
       // Handle message according to backpressure strategy
       if (backpressureManager.isBackpressureActive()) {
           return backpressureManager.handleMessage(message, options);
       }
       
       // No backpressure, accept message normally
       mailbox.offer(message);
       return true;
   }
   
   // Update metrics periodically
   private void updateBackpressureMetrics() {
       if (backpressureManager != null) {
           backpressureManager.updateMetrics(
               mailbox.size(),           // Current mailbox size
               getMailboxCapacity(),     // Mailbox capacity
               getProcessingRate()       // Messages processed per second
           );
       }
   }
   ```

3. **Performance Metrics Collection**:
   ```java
   // Add to Actor
   private final AtomicLong messagesProcessed = new AtomicLong(0);
   private final AtomicLong processingTimeNanos = new AtomicLong(0);
   private final AtomicLong lastReportTime = new AtomicLong(System.currentTimeMillis());
   
   @Override
   protected void receive(Message message) {
       long startTime = System.nanoTime();
       try {
           actualReceive(message);
       } finally {
           long elapsed = System.nanoTime() - startTime;
           messagesProcessed.incrementAndGet();
           processingTimeNanos.addAndGet(elapsed);
           
           // Periodically log metrics
           long now = System.currentTimeMillis();
           long last = lastReportTime.get();
           if (now - last > 60000 && lastReportTime.compareAndSet(last, now)) {
               logPerformanceMetrics();
           }
       }
   }
   
   private void logPerformanceMetrics() {
       long count = messagesProcessed.get();
       long timeNanos = processingTimeNanos.get();
       double avgProcessingTimeMs = count > 0 ? (timeNanos / 1_000_000.0) / count : 0;
       
       logger.info("Actor {} metrics: processed {} messages, avg processing time: {} ms", 
                  getActorId(), count, avgProcessingTimeMs);
   }
   ```

## Implementation Strategy

For implementing these recommendations, we suggest the following phased approach:

### Phase 1: Quick Wins
1. Implement batch collection reuse in `Actor.processMailbox()`
2. Add the workload-specific thread pool configurations
3. Implement delayed state persistence for `StatefulActor`

### Phase 2: Medium-Term Improvements
1. Add message prioritization
2. Implement connection pooling for cluster communication
3. Add basic performance metrics collection

### Phase 3: Long-Term Architectural Enhancements
1. Implement message batching for network communication
2. Replace serialization with more efficient alternatives
3. Add adaptive batch sizing and auto-tuning capabilities

## Conclusion

The Cajun actor system has a solid foundation with good performance characteristics, but these recommendations can help optimize it further for high-throughput and low-latency scenarios. The most significant gains will likely come from:

1. Optimizing network communication in the cluster mode
2. Improving state persistence patterns
3. Fine-tuning thread pool configurations for specific workloads

By implementing these recommendations, the system should be able to handle higher message throughput with lower latency and better resource utilization.
